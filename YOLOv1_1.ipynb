{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dietary-portugal",
   "metadata": {},
   "source": [
    "# 数据提取和转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abroad-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "CLASSES = ['person', 'bird', 'cat', 'cow', 'dog', 'horse', 'sheep',\n",
    "           'aeroplane', 'bicycle', 'boat', 'bus', 'car', 'motorbike', 'train',\n",
    "           'bottle', 'chair', 'dining table', 'potted plant', 'sofa', 'tvmonitor']\n",
    "num_bbox = 2\n",
    "\n",
    "dataset = r'/home/yuzhengbo/文档/VOCdevkit/VOC2012'\n",
    "\n",
    "def convert(size,box):\n",
    "    w_ = size[0]\n",
    "    h_ = size[1]\n",
    "    x = (box[0]+box[2])/2.\n",
    "    y = (box[1]+box[3])/2.\n",
    "    w = box[2]-box[0]\n",
    "    h = box[3]-box[1]\n",
    "    return x/w_,y/h_,w/w_,h/h_\n",
    "    \n",
    "def convert_annotation(image_id):\n",
    "    in_file = open(dataset+'/Annotations'+'/%s'%image_id)\n",
    "    image_id = image_id.split('.')[0]\n",
    "    out_file = open(dataset+'/labels/%s.txt'%image_id,'w+')\n",
    "    tree = ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "    size = root.find('size')\n",
    "    width = float(size.find('width').text)\n",
    "    height = float(size.find('height').text)\n",
    "    \n",
    "    for obj in root.iter('object'):\n",
    "        name = obj.find('name').text\n",
    "        difficult = obj.find('difficult')\n",
    "        if name not in CLASSES or difficult==1:\n",
    "            continue\n",
    "        cls_id = CLASSES.index(name)\n",
    "        bndbox = obj.find('bndbox')\n",
    "        box = (float(bndbox.find('xmin').text),float(bndbox.find('ymin').text),\n",
    "                      float(bndbox.find('xmax').text),float(bndbox.find('ymax').text))\n",
    "        text_ = convert([width,height],box)\n",
    "        out_file.write(str(cls_id)+' '+' '.join([str(i) for i in text_])+'\\n')\n",
    "# convert_annotation('2007_000027.xml')\n",
    "\n",
    "# for i in os.listdir(dataset+'/Annotations'):\n",
    "#     convert_annotation(i)\n",
    "# print('convert finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "killing-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_labels_img(imgname):\n",
    "#     print(dataset + \"JPEGImages/\" + imgname + \".jpg\")\n",
    "#     img = cv2.imread(dataset + \"/JPEGImages/\" + imgname + \".jpg\")\n",
    "#     h, w = img.shape[:2]\n",
    "#     print(w,h)\n",
    "#     label = []\n",
    "#     with open(dataset+'/labels/'+imgname+\".txt\",'r') as flabel:\n",
    "#         for label in flabel:\n",
    "#             label = label.split(' ')\n",
    "#             label = [float(x.strip()) for x in label]\n",
    "#             print(CLASSES[int(label[0])])\n",
    "#             pt1 = (int(label[1] * w - label[3] * w / 2), int(label[2] * h - label[4] * h / 2))\n",
    "#             pt2 = (int(label[1] * w + label[3] * w / 2), int(label[2] * h + label[4] * h / 2))\n",
    "#             cv2.putText(img,CLASSES[int(label[0])],pt1,cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255))\n",
    "#             cv2.rectangle(img,pt1,pt2,(0,0,255,2))\n",
    "\n",
    "#     cv2.imshow(\"img\",img)\n",
    "#     cv2.waitKey(0)\n",
    "# #     cv2.destroyAllWindows()\n",
    "# show_labels_img('2007_000027')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "traditional-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "class VOC2012(Dataset):\n",
    "    def __init__(self,is_train=True,is_aug=True):\n",
    "        self.filenames = []\n",
    "        if is_train:\n",
    "            with open(dataset+'/ImageSets/Main/train.txt','r') as f:\n",
    "                self.filenames = [x.strip() for x in f]\n",
    "        else:\n",
    "            with open(dataset+'/ImageSets/Main/val.txt','r') as f:\n",
    "                self.filenames = [x.strip() for x in f]\n",
    "                \n",
    "        self.imgpath = dataset+'/JPEGImages/'\n",
    "        self.labelpath = dataset+'/labels/'\n",
    "        self.is_aug = is_aug\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        img = cv2.imread(self.imgpath+self.filenames[item]+'.jpg')\n",
    "        h,w = img.shape[:2]\n",
    "        input_size = 448\n",
    "        padw,padh = 0,0\n",
    "        if h>w:\n",
    "            padw = (h-w)//2\n",
    "            img = np.pad(img,((0,0),(padw,padw),(0,0)),'constant',constant_values=0)\n",
    "        elif w>h:\n",
    "            padh = (w-h)//2\n",
    "            img = np.pad(img,((padh,padh),(0,0),(0,0)),'constant',constant_values=0)\n",
    "        img = cv2.resize(img,(input_size,input_size))\n",
    "        \n",
    "        if self.is_aug:\n",
    "            aug = transforms.Compose([\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "            img = aug(img)\n",
    "            \n",
    "        with open(self.labelpath+self.filenames[item]+'.txt')as f:\n",
    "            bbox = f.read().split('\\n')\n",
    "            bbox = [x.split() for x in bbox]\n",
    "            bbox = [float(y) for x in bbox for y in x]\n",
    "\n",
    "            if len(bbox)%5!=0:\n",
    "                raise ValueError('file:'+self.labelpath+self.filenames[item]+'.txt'+'has some questions!')\n",
    "        for i in range(len(bbox)//5):\n",
    "            if padw!=0:\n",
    "                bbox[i*5+1] = (bbox[i*5+1]*w+padw)/h\n",
    "                bbox[i*5+3] = (bbox[i*5+3]*w)/h\n",
    "            elif padh!=0:\n",
    "                bbox[i * 5 + 2] = (bbox[i * 5 + 2] * h + padh) / w\n",
    "                bbox[i * 5 + 4] = (bbox[i * 5 + 4] * h) / w\n",
    "                \n",
    "        labels = convert_bbox2labels(bbox)\n",
    "        labels = transforms.ToTensor()(labels)\n",
    "        return img,labels\n",
    "def convert_bbox2labels(bbox):\n",
    "    gridsize = 1.0/7\n",
    "    labels = np.zeros((7,7,5*num_bbox+len(CLASSES)))\n",
    "    for i in range(len(bbox)//5):\n",
    "        #目标区域中心点所在最后feature map的位置\n",
    "        gridx = int(bbox[i*5+1]//gridsize)\n",
    "        gridy = int(bbox[i*5+2]//gridsize)\n",
    "        #目标区域中心相对于所在feature map网格左上方坐标的偏移值\n",
    "        gridpx = bbox[i * 5 + 1] / gridsize - gridx\n",
    "        gridpy = bbox[i * 5 + 2] / gridsize - gridy\n",
    "            \n",
    "        labels[gridy,gridx,0:5] = np.array([gridpx,gridpy,bbox[i*5+3],bbox[i*5+4],1])\n",
    "        labels[gridy,gridx,5:10] = np.array([gridpx,gridpy,bbox[i*5+3],bbox[i*5+4],1])\n",
    "        labels[gridy,gridx,int(bbox[i*5])+10] = 1\n",
    "    return labels      #其中labels的两个预测目标位置都是相同的\n",
    "    \n",
    "# voc = VOC2012()\n",
    "# img,labels = voc.__getitem__(1)\n",
    "# print(img.shape,labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caring-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_yolov1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Loss_yolov1).__init__()\n",
    "        \n",
    "    def forward(self,pred,labels):      #其中30这一列数据分别表示（x1,y1,w1,h1,confi)*2+classes\n",
    "        # pred和labels的形状都是（batch_size,30,7,7)\n",
    "        num_gridx,num_gridy = labels.shape[-2:]\n",
    "        num_b = 2\n",
    "        num_cls = 20\n",
    "        noobj_confi_loss = 0     #无检测目标的置信度损失\n",
    "        coor_loss = 0            #含有目标的坐标损失\n",
    "        obj_confi_loss = 0       #有目标的置信度损失\n",
    "        class_loss = 0           #目标类别的置信度损失\n",
    "        n_batch = labels.shape[0]\n",
    "        \n",
    "        for i in range(n_batch):\n",
    "            for n in range(7):    #x方向的循环\n",
    "                for m in range(7):\n",
    "                    if labels[i,4,m,n] == 1:\n",
    "                        bbox1_pred_xyxy = ((pred[i,0,m,n]+n)/num_gridx - pred[i,2,m,n]/2,(pred[i,1,m,n]+m)/num_gridy - pred[i,3,m,n]/2,\n",
    "                                           (pred[i,0,m,n]+n)/num_gridx + pred[i,2,m,n]/2,(pred[i,1,m,n]+m)/num_gridy + pred[i,3,m,n]/2)\n",
    "                        bbox2_pred_xyxy = ((pred[i,5,m,n]+n)/num_gridx - pred[i,7,m,n]/2,(pred[i,6,m,n]+m)/num_gridy - pred[i,8,m,n]/2,\n",
    "                                           (pred[i,5,m,n]+n)/num_gridx + pred[i,7,m,n]/2,(pred[i,6,m,n]+m)/num_gridy + pred[i,8,m,n]/2)\n",
    "                        bbox_gt_xyxy = ((labels[i,0,m,n]+n)/num_gridx - labels[i,2,m,n]/2,(labels[i,1,m,n]+m)/num_gridy - labels[i,3,m,n]/2,\n",
    "                                        (labels[i,0,m,n]+n)/num_gridx + labels[i,2,m,n]/2,(labels[i,1,m,n]+m)/num_gridy + labels[i,3,m,n]/2)\n",
    "                        \n",
    "                        iou1 = calculate_iou(bbox1_pred_xyxy,bbox_gt_xyxy)\n",
    "                        iou2 = calculate_iou(bbox2_pred_xyxy,bbox_gt_xyxy)\n",
    "                        if iou1>iou2:\n",
    "                            coor_loss += 5*(torch.sum((pred[i,0:2,m,n]-labels[i,0:2,m,n])**2)+\n",
    "                                           torch.sum((pred[i,2:4,m,n].sqrt()-labels[i,2:4,m,n].sqrt())**2))\n",
    "                            obj_confi_loss += (pred[i,4,m,n]-iou1)**2              #IOU即是置信度\n",
    "                            noobj_confi_loss += 0.5*((pred[i,9,m,n]-iou2)**2)     #没感觉到这两个损失函数的作用\n",
    "                        else:            \n",
    "                            coor_loss += 5*(torch.sum((pred[i,5:7,m,n]-labels[i,5:7,m,n])**2)+\n",
    "                                           torch.sum((pred[i,7:9,m,n].sqrt()-labels[i,7:9,m,n].sqrt())**2))\n",
    "                            obj_confi_loss += (pred[i,9,m,n]-iou2)**2\n",
    "                            noobj_confi_loss += 0.5*((pred[i,4,m,n]-iou1)**2)\n",
    "                        class_loss += torch.sum((pred[i,10:,m,n]-labels[i,10:,m,n])**2)\n",
    "                    else:\n",
    "                        #没有目标的情况下\n",
    "                        noobj_confi_loss += 0.5*torch.sum(pred[i,[4,9],m,n]**2)\n",
    "        loss =  coor_loss + obj_confi_loss + noobj_confi_loss + class_loss\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "#计算IOU函数的设计\n",
    "\n",
    "def calculate_iou(bbox1,bbox2):\n",
    "    intersect_bbox = [0,0,0,0]\n",
    "    if bbox1[2]<bbox2[0] or bbox1[3]<bbox2[1] or bbox1[0]>bbox2[2] or bbox1[1]>bbox2[3]:\n",
    "          return 0\n",
    "    else:\n",
    "        intersect_bbox[0] = max(bbox1[0],bbox2[0])\n",
    "        intersect_bbox[1] = max(bbox1[1],bbox2[1])\n",
    "        intersect_bbox[2] = min(bbox1[2],bbox2[2])\n",
    "        intersect_bbox[3] = min(bbox1[3],bbox2[3])\n",
    "    \n",
    "    area1 = (bbox1[2]-bbox1[0])*(bbox1[3]-bbox1[1])\n",
    "    area2 = (bbox2[2]-bbox2[0])*(bbox2[3]-bbox2[1])\n",
    "    area_inter = (intersect_bbox[2]-intersect_bbox[0])*(intersect_bbox[3]-intersect_bbox[1])\n",
    "    \n",
    "    if area_inter>0:\n",
    "        return area_inter/(area1+area2-area_inter)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "# pred = torch.from_numpy(np.ones((1,30,7,7)))\n",
    "# labels = torch.from_numpy(np.expand_dims(labels,axis=0))\n",
    "# type(pred),type(labels),pred.shape,labels.shape\n",
    "\n",
    "# loss = Loss_yolov1()\n",
    "# loss.forward(pred,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reasonable-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "#网络模型搭建\n",
    "import torchvision.models as tvmodel\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class YOLOv1_resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YOLOv1_resnet,self).__init__()\n",
    "        resnet = tvmodel.resnet34(pretrained=True)    \n",
    "        resnet_out_channel = resnet.fc.in_features\n",
    "        #使用resnet网络的卷积层\n",
    "        self.resnet = nn.Sequential(*list(resnet.children())[:-2])           \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(resnet_out_channel,1024,3,padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(1024,1024,3,stride=2,padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(1024,1024,3,padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(1024,1024,3,padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1024*7*7,4096),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(4096,7*7*30),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.resnet(x)\n",
    "        x= self.conv_layers(x)\n",
    "        x = x.view(x.size()[0],-1)\n",
    "        output = self.fc(x)\n",
    "        return output.reshape(-1,(5*num_bbox+len(CLASSES)),7,7)\n",
    "        \n",
    "# YOLO = YOLOv1_resnet()\n",
    "# YOLO(torch.ones((1,3,448,448))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-worker",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/50| Step 0/1143| Loss: 147.40\n",
      "Epoch 0/50| Step 1/1143| Loss: 108.09\n",
      "Epoch 0/50| Step 2/1143| Loss: 116.86\n",
      "Epoch 0/50| Step 3/1143| Loss: 88.00\n",
      "Epoch 0/50| Step 4/1143| Loss: 78.12\n",
      "Epoch 0/50| Step 5/1143| Loss: 94.34\n",
      "Epoch 0/50| Step 6/1143| Loss: 80.31\n",
      "Epoch 0/50| Step 7/1143| Loss: 88.14\n",
      "Epoch 0/50| Step 8/1143| Loss: 33.84\n",
      "Epoch 0/50| Step 9/1143| Loss: 67.07\n",
      "Epoch 0/50| Step 10/1143| Loss: 65.99\n",
      "Epoch 0/50| Step 11/1143| Loss: 26.87\n",
      "Epoch 0/50| Step 12/1143| Loss: 22.47\n",
      "Epoch 0/50| Step 13/1143| Loss: 23.53\n",
      "Epoch 0/50| Step 14/1143| Loss: 53.30\n",
      "Epoch 0/50| Step 15/1143| Loss: 61.59\n",
      "Epoch 0/50| Step 16/1143| Loss: 24.81\n",
      "Epoch 0/50| Step 17/1143| Loss: 50.04\n",
      "Epoch 0/50| Step 18/1143| Loss: 55.48\n",
      "Epoch 0/50| Step 19/1143| Loss: 23.82\n",
      "Epoch 0/50| Step 20/1143| Loss: 48.11\n",
      "Epoch 0/50| Step 21/1143| Loss: 36.19\n",
      "Epoch 0/50| Step 22/1143| Loss: 29.16\n",
      "Epoch 0/50| Step 23/1143| Loss: 69.67\n",
      "Epoch 0/50| Step 24/1143| Loss: 28.88\n",
      "Epoch 0/50| Step 25/1143| Loss: 50.33\n",
      "Epoch 0/50| Step 26/1143| Loss: 41.45\n",
      "Epoch 0/50| Step 27/1143| Loss: 51.10\n",
      "Epoch 0/50| Step 28/1143| Loss: 41.59\n",
      "Epoch 0/50| Step 29/1143| Loss: 43.28\n",
      "Epoch 0/50| Step 30/1143| Loss: 52.23\n",
      "Epoch 0/50| Step 31/1143| Loss: 27.72\n",
      "Epoch 0/50| Step 32/1143| Loss: 94.94\n",
      "Epoch 0/50| Step 33/1143| Loss: 57.09\n",
      "Epoch 0/50| Step 34/1143| Loss: 39.01\n",
      "Epoch 0/50| Step 35/1143| Loss: 73.54\n",
      "Epoch 0/50| Step 36/1143| Loss: 26.97\n",
      "Epoch 0/50| Step 37/1143| Loss: 58.17\n",
      "Epoch 0/50| Step 38/1143| Loss: 46.38\n",
      "Epoch 0/50| Step 39/1143| Loss: 35.63\n",
      "Epoch 0/50| Step 40/1143| Loss: 36.04\n",
      "Epoch 0/50| Step 41/1143| Loss: 61.11\n",
      "Epoch 0/50| Step 42/1143| Loss: 84.69\n",
      "Epoch 0/50| Step 43/1143| Loss: 64.01\n",
      "Epoch 0/50| Step 44/1143| Loss: 62.91\n",
      "Epoch 0/50| Step 45/1143| Loss: 75.13\n",
      "Epoch 0/50| Step 46/1143| Loss: 31.94\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "import visdom\n",
    "from torch.utils.data import DataLoader\n",
    "epoch = 50\n",
    "batchsize = 5\n",
    "lr = 0.0001\n",
    "is_vis = False\n",
    "\n",
    "train_data = VOC2012()\n",
    "train_dataloader = DataLoader(VOC2012(is_train=True),batch_size=batchsize,shuffle=True)\n",
    "\n",
    "model = YOLOv1_resnet().cuda()\n",
    "\n",
    "#将resnet网络部分冻结,整个网络有三个部分(resnet部分,自己定义的卷积结构以及全连接结构)\n",
    "for layer in model.children():\n",
    "    layer.requires_grad = False\n",
    "    break\n",
    "\n",
    "criterion = Loss_yolov1()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=lr,momentum=0.9,weight_decay=0.0005)\n",
    "if is_vis:\n",
    "    vis = visdom.Visdom()\n",
    "    viswin1 = vis.line(np.array([0.]),np.array([0.]),opts=dict(title='Loss/Step',xlabel='100*step',ylabel='Loss'))\n",
    "\n",
    "for e in range(epoch):\n",
    "    model.train()\n",
    "    y1 = torch.Tensor([0.]).cuda()\n",
    "    for i,(inputs,labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.float().cuda()\n",
    "        pred = model(inputs)\n",
    "        loss = criterion.forward(pred,labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"Epoch %d/%d| Step %d/%d| Loss: %.2f\"%(e,epoch,i,len(train_data)//batchsize,loss))\n",
    "        y1 += loss\n",
    "        if is_vis and (i+1)%100==0:\n",
    "            vis.line(np.array([yl.cpu().item()/(i+1)]),np.array([i+e*len(train_data)//batchsize]),win=viswin1,update='append')\n",
    "    if (e+1)%10 == 0:\n",
    "        torch.save(model,'./models_pkl/YOLOv1_epoch'+str(e+1)+'.pkl')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-italic",
   "metadata": {},
   "source": [
    "# 网络预测\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels2bbox(matrix):\n",
    "    #将matrix由（7，7，30）转变成为（98，25）\n",
    "    if maxtrix.size()[:2] != (7,7):\n",
    "        raise ValueError('Error:Wrong with labels size:',matrix.size())\n",
    "    bbox = torch.zeros((98,25))\n",
    "    for i in range(7):      #y方向\n",
    "        for j in range(7):\n",
    "            bbox[2*(i*7+j),:4] = torch.Tersor([(matrix[i,j,0]+j)/7-matrix[i,j,2]/2,(matrix[i,j,1]+i)/7-matrix[i,j,3]/2,\n",
    "                                              (matrix[i,j,0]+j)/7+matrix[i,j,2]/2,(matrix[i,j,1]+i)/7+matrix[i,j,3]/2])\n",
    "            bbox[2*(i*7+j),4] = matrix[i,j,4]\n",
    "            bbox[2*(i*7+j),5:] = matrix[i,j,10:]\n",
    "            \n",
    "            bbox[2*(i*7+j)+1,:4] = torch.Tersor([(matrix[i,j,5]+j)/7-matrix[i,j,7]/2,(matrix[i,j,6]+i)/7-matrix[i,j,8]/2,\n",
    "                                              (matrix[i,j,5]+j)/7+matrix[i,j,7]/2,(matrix[i,j,6]+i)/7+matrix[i,j,8]/2])\n",
    "            bbox[2*(i*7+j)+1,4] = matrix[i,j,9]\n",
    "            bbox[2*(i*7+j)+1,5:] = matrix[i,j,10:]\n",
    "    return NMS(bbox)\n",
    "\n",
    "\n",
    "def NMS(bbox,conf_tresh=0.1,iou_thresh=0.3):\n",
    "    n = bbox.size()[0]\n",
    "    bbox_prob = bbox[:,5:].clone()\n",
    "    bbox_confi = bbox[:,4].clone().unsqueeze(1).expand_as(bbox_prob)\n",
    "    bbox_cls_spec_conf = bbox_confi*bbox_prob\n",
    "    bbox_cls_spec_conf[bbox_cls_spec_cong<conf_tresh] = 0\n",
    "    for c in range(20):\n",
    "        rank = torch.sort(bbox_cls_spec_conf[:,c],descending=True).indices\n",
    "        for i in range(98):\n",
    "            if bbox_cls_spec_conf[rank[i],c] != 0:\n",
    "                for j in range(i+1,98):\n",
    "                    if bbox_cls_spec_conf[rank[j],c] != 0:\n",
    "                        iou = calculate_iou(bbox[rank[i],:4],bbox[rank[j],:4])\n",
    "                        if iou>iou_thresh:\n",
    "                            bbox_cls_spec_conf[rank[j],c] = 0\n",
    "                    else:\n",
    "                        break\n",
    "    bbox = bbox[torch.max(bbox_cls_spec_conf,dim=1).values>0] \n",
    "    bbox_cls_spec_conf = bbox_cls_spec_conf[torch.max(bbox_cls_spec_conf,axis=1).values>0]\n",
    "    result = torch.zeros((bbox.size()[0],6))\n",
    "    result[:,1:5] = bbox[:,:4]\n",
    "    result[:,0] = torch.argmax(bbox[:,5:],axis=1).int()\n",
    "    result[:,5] = torch.max(bbox_cls_spec_conf,axis=1).values\n",
    "    return result\n",
    "\n",
    "def draw_bbox(img,bbox):\n",
    "    h,w = img.shape[:2]\n",
    "    n = bbox.size()[0]\n",
    "#     print(bbox)\n",
    "    for i in range(n):\n",
    "        p1 = (bbox[i,1]*w,bbox[i,2]*h)\n",
    "        p2 = (bbox[i,3]*w,bbox[i,4]*h)\n",
    "        cls_name = CLASSES[int(bbox[i,0])]\n",
    "        confidence = bbox[i,5]\n",
    "        cv2.rectangle(img,p1,p2,color=COLOR[int(bbox[i,0])])\n",
    "        cv2.putText(img,cls_name,p1,cv.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255))\n",
    "    cv2.imshow('bbox',img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "\n",
    "\n",
    "COLOR = [(255,0,0),(255,125,0),(255,255,0),(255,0,125),(255,0,250),\n",
    "         (255,125,125),(255,125,250),(125,125,0),(0,255,125),(255,0,0),\n",
    "         (0,0,255),(125,0,255),(0,125,255),(0,255,255),(125,125,255),\n",
    "         (0,255,0),(125,255,125),(255,255,255),(100,100,100),(0,0,0),] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(VOC2012(is_train=False),batch_size=1,shuffle=False)\n",
    "\n",
    "model = torch.load('./models_pkl/YOLOv1_epoch50.pkl')\n",
    "for i,(inputs,labels) in enumerate(val_dataloader):\n",
    "    inputs = inputs.cuda()\n",
    "    pred = model(inputs)\n",
    "    pred = pred.squeeze(dim=0)   #压缩为30，7，7本来应该是（1，30，7，7）\n",
    "    pred = pred.permute((1,2,0))   #转变为（7，7，30）\n",
    "    \n",
    "    bbox = labels2bbox(pred)\n",
    "    inputs = inputs.squeeze(dim=0)\n",
    "    inputs = inputs.permute((1,2,0))  #转换为(448,448,3)\n",
    "    img = inputs.cpu().numpy()\n",
    "    img = 255*img\n",
    "    img = img.astype(np.uint(8))\n",
    "    draw_bbox(img,bbox.cpu())\n",
    "#     print(bbox.size(),bbox)\n",
    "#     with open(dataset+'/pre_labels')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
